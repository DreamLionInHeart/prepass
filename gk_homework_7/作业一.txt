如何避免小文件问题？给出2～3种解决方案：

1.在最终输出数据时，减少 task 的数目，如 repartition
2.Sequence file 由一系列的二进制key/value组成，如果为key小文件名，value为文件内容，则可以将 大批小文件合并成一个大文件。
3.如果 Spark 写入到 Hive orc 表，还可以使用 Hive 的 alter table table_name partition(...) CONCATENATE ; 合并分区下的小文件
4.使用 hudi 提供的小文件合并功能

